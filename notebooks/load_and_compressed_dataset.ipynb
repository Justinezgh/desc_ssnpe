{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "5659c905-7148-4a9b-8769-2f8b8c10b9a9",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/gpfslocalsup/pub/anaconda-py3/2022.05/envs/tensorflow-gpu-2.11.0+py3.10.8/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "2023-07-15 23:49:16.583299: I tensorflow/core/platform/cpu_feature_guard.cc:193] This TensorFlow binary is optimized with oneAPI Deep Neural Network Library (oneDNN) to use the following CPU instructions in performance-critical operations:  SSE3 SSE4.1 SSE4.2 AVX AVX2 AVX512F AVX512_VNNI FMA\n",
      "To enable them in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-07-15 23:49:16.761087: I tensorflow/core/util/port.cc:104] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "%pylab is deprecated, use %matplotlib inline and import the required libraries.\n",
      "Populating the interactive namespace from numpy and matplotlib\n"
     ]
    }
   ],
   "source": [
    "import tensorflow_datasets as tfds\n",
    "import tensorflow as tf\n",
    "from sbi_lens.gen_dataset.lensing_lognormal_dataset import LensingLogNormalDataset\n",
    "%pylab inline \n",
    "import jax.numpy as jnp\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c4463883-d705-48bb-a832-516b75ea3855",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c5da3026-3219-418b-908d-c6064ff01087",
   "metadata": {},
   "outputs": [],
   "source": [
    "gpus = tf.config.experimental.list_physical_devices(device_type='GPU')\n",
    "\n",
    "for gpu in gpus:\n",
    "    tf.config.experimental.set_memory_growth(gpu, True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42653709-b422-40ef-87b7-281fef357383",
   "metadata": {},
   "source": [
    "# Pre load and compress dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6cbb1316-6a1c-4431-980a-110326df591b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import haiku as hk\n",
    "from haiku._src.nets.resnet import ResNet18\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1d9ea387-4f75-44d8-909e-9fcb42f67e47",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## COMPRESSOR ########\n"
     ]
    }
   ],
   "source": [
    "######## COMPRESSOR ########\n",
    "print('######## COMPRESSOR ########')\n",
    "\n",
    "compressor = hk.transform_with_state(\n",
    "    lambda y : ResNet18(dim)(y, is_training=False)\n",
    ")\n",
    "\n",
    "a_file = open('./data/params_compressor/opt_state_resnet_vmim.pkl', \"rb\") \n",
    "opt_state_resnet= pickle.load(a_file)\n",
    "\n",
    "a_file = open('./data/params_compressor/params_nd_compressor_vmim.pkl', \"rb\")\n",
    "parameters_compressor= pickle.load(a_file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f18fb0a0-f711-499d-8fc9-de7cec25d09d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You use TensorFlow DType <dtype: 'float32'> in tfds.features This will soon be deprecated in favor of NumPy DTypes. In the meantime it was converted to float32.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## TRAIN ########\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-07-15 23:49:08.712705: I tensorflow/core/common_runtime/gpu/gpu_device.cc:1613] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 1753 MB memory:  -> device: 0, name: Tesla V100-SXM2-32GB, pci bus id: 0000:1a:00.0, compute capability: 7.0\n"
     ]
    }
   ],
   "source": [
    "from sbi_lens.gen_dataset import lensing_lognormal_dataset\n",
    "batch_size = 128\n",
    "dim = 6\n",
    "\n",
    "ds = tfds.load(\n",
    "    'LensingLogNormalDataset/year_10_with_noise_score_density_proposal',\n",
    "    split='train'\n",
    ")\n",
    "ds = ds.batch(batch_size)\n",
    "\n",
    "iter = ds.as_numpy_iterator()\n",
    "\n",
    "y = []\n",
    "theta = []\n",
    "score = []\n",
    "\n",
    "for example in iter:\n",
    "  # compress the maps into a summary\n",
    "  comp_y,_ = compressor.apply(\n",
    "      parameters_compressor,\n",
    "      opt_state_resnet,\n",
    "      None,\n",
    "      example['simulation']\n",
    "    )\n",
    "  y.append(comp_y)\n",
    "  theta.append(example['theta'])\n",
    "  score.append(example['score'])\n",
    "dataset = {\n",
    "    'theta': np.concatenate(theta, axis=0), \n",
    "    'score': np.concatenate(score, axis=0), \n",
    "    'y': np.concatenate(y, axis=0), \n",
    "}\n",
    "# saving the dataset\n",
    "np.savez('LOADED&COMPRESSED_year_10_with_noise_score_density_proposal.npz', dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "28cad958-2ac4-40da-8b07-ff81b237ed35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######## TRAIN ########\n"
     ]
    }
   ],
   "source": [
    "from sbi_lens.gen_dataset import lensing_lognormal_dataset\n",
    "batch_size = 128\n",
    "dim = 6\n",
    "\n",
    "ds = tfds.load(\n",
    "    'LensingLogNormalDataset/year_10_with_noise_score_density',\n",
    "    split='train'\n",
    ")\n",
    "ds = ds.batch(batch_size)\n",
    "\n",
    "iter = ds.as_numpy_iterator()\n",
    "\n",
    "y = []\n",
    "theta = []\n",
    "score = []\n",
    "\n",
    "for example in iter:\n",
    "  # compress the maps into a summary\n",
    "  comp_y,_ = compressor.apply(\n",
    "      parameters_compressor,\n",
    "      opt_state_resnet,\n",
    "      None,\n",
    "      example['simulation']\n",
    "    )\n",
    "  y.append(comp_y)\n",
    "  theta.append(example['theta'])\n",
    "  score.append(example['score'])\n",
    "dataset = {\n",
    "    'theta': np.concatenate(theta, axis=0), \n",
    "    'score': np.concatenate(score, axis=0), \n",
    "    'y': np.concatenate(y, axis=0), \n",
    "}\n",
    "# saving the dataset\n",
    "np.savez('LOADED&COMPRESSED_year_10_with_noise_score_density.npz', dataset)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tensorflow-gpu-2.11.0_py3.10.8",
   "language": "python",
   "name": "module-conda-env-tensorflow-gpu-2.11.0_py3.10.8"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
